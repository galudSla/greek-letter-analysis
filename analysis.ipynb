{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOKqg6gTdW0zdK59x2w2i9r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/galudSla/greek-letter-analysis/blob/main/analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Libraries"
      ],
      "metadata": {
        "id": "XyDrRxMxBo6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import progressbar\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "import pandas as pd\n",
        "from collections import OrderedDict\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "from google.colab import files\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "FpxqMfQ-fYCc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4acf2819-8133-4aac-d49b-3040ff3bee2e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the upload part till the preprocessing is skipped due to the very large dataset size (over 80GB) and has been done offline, the code is here for reference and the results and preprocessing is done with the el_unique.txt which holds all the unique words of the dataset."
      ],
      "metadata": {
        "id": "MOQYQy2jJjIM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "d6c_xU49VRCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tone_dict = {\n",
        "    'ά': 'α',\n",
        "    'έ': 'ε',\n",
        "    'ύ': 'υ',\n",
        "    'ώ': 'ω',\n",
        "    'ή': 'η',\n",
        "    'ί': 'ι',\n",
        "    'ό': 'ο',\n",
        "    'ϊ': 'ι',\n",
        "    'ΐ': 'ι'\n",
        "}"
      ],
      "metadata": {
        "id": "fISvbnSKH5fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Append text to string in chunks.Lower case the loaded string, punctuation and number in string removal. Replacement of toned letters with the same without the tone."
      ],
      "metadata": {
        "id": "J1EqWmr8B4uR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = {}\n",
        "count_all = 0\n",
        "with open(\"E:\\\\Downloads\\\\el\\\\el.txt\", 'r', encoding='utf-8') as f:\n",
        "    for chunk in tqdm(iter(lambda: f.read(16777216), ''), total= 3015):\n",
        "\n",
        "        for i in string.punctuation+'0123456789':\n",
        "            chunk = chunk.replace(i, '')\n",
        "        for key,val in tone_dict.items():\n",
        "            chunk = chunk.replace(key, val)\n",
        "\n",
        "        chunk = chunk.lower()\n",
        "        temp = word_tokenize(chunk)\n",
        "        count_all += len(temp)\n",
        "\n",
        "        for word in temp:\n",
        "            if word not in words.keys():\n",
        "                words[word] = 1\n",
        "            else:\n",
        "                words[word] += 1"
      ],
      "metadata": {
        "id": "LvTBz1dTVuAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('el_unique.txt', 'w', encoding='utf-8') as f:\n",
        "    write = csv.writer(f)\n",
        "    write.writerow(words.keys())\n",
        "\n",
        "with open('el_frequency', 'w', encoding='utf-8') as f:\n",
        "    write = csv.writer(f)\n",
        "    write.writerow(words.values())"
      ],
      "metadata": {
        "id": "qIGFH-aOXs7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "preprocessing"
      ],
      "metadata": {
        "id": "RucbTQhgJInt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtUoKYs4JH_3",
        "outputId": "fa84a959-52be-4524-df9c-6a66c07ab7d7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/Colab Notebooks/Greek Letter Analysis /el_unique.txt', encoding='utf-8') as f:\n",
        "    words = f.read().rstrip('\\n')"
      ],
      "metadata": {
        "id": "Snlua9M5KZbf"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = word_tokenize(words)\n",
        "words = list(set(words))\n",
        "words = [i for i in words if len(i)>2]"
      ],
      "metadata": {
        "id": "-6R4W68OZMiv"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bar = progressbar.ProgressBar(maxval=len(words)).start()\n",
        "greek_pattern = re.compile(r'^[α-ω]{1,24}$')\n",
        "clean_words = []\n",
        "for i,word in enumerate(words):\n",
        "    if greek_pattern.match(word):\n",
        "        word = word.replace(\"ς\", \"σ\")\n",
        "        clean_words.append(word.strip())\n",
        "    bar.update(i+1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WduLqzGmRku4",
        "outputId": "9e78a147-5dec-433c-dfbd-a8b4474edd19"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99% (13846389 of 13856197) |########### | Elapsed Time: 0:00:43 ETA:   0:00:00"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/Colab Notebooks/Greek Letter Analysis/final.txt', 'w', encoding='utf-8') as f:\n",
        "    write = csv.writer(f)\n",
        "    write.writerow(clean_words)"
      ],
      "metadata": {
        "id": "P8oxgBqJTvBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "dictionary that holds the number of each letter appearence"
      ],
      "metadata": {
        "id": "OolKguguCfqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "letter_dict = {}\n",
        "total_letters = 0\n",
        "for i in range(len(words)):\n",
        "    for j in words[i]:\n",
        "        if j not in letter_dict.keys():\n",
        "            letter_dict[j] = 1\n",
        "            total_letters += 1\n",
        "        else:\n",
        "            letter_dict[j] += 1\n",
        "            total_letters += 1\n",
        "    bar.update(i+1)\n",
        "\n",
        "letter_dict = dict(sorted(letter_dict.items()))"
      ],
      "metadata": {
        "id": "O1qQPcghf29r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76c0471d-b9ec-4455-9432-d4319473ae58"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100% (13856197 of 13856197) |############| Elapsed Time: 0:16:34 ETA:  00:00:00"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "letter_dict"
      ],
      "metadata": {
        "id": "7K9DYThSXUEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bar plot for letter appearence"
      ],
      "metadata": {
        "id": "EF9WbO6yCnn0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "names = list(letter_dict.keys())\n",
        "values = list(letter_dict.values())\n",
        "\n",
        "plt.bar(range(len(letter_dict)), values, tick_label=names)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rJxhWnoe_wAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Letter appearence percentage calculation and dictionary mapping"
      ],
      "metadata": {
        "id": "X330d4qIDIk5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "letter_percentage_dic = {}\n",
        "for key in letter_dict:\n",
        "    letter_percentage_dic[key] = round(letter_dict[key]/total_letters*100, 2)"
      ],
      "metadata": {
        "id": "35-tXrVajvNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dictionary with the appearence of the letter that follows another letter"
      ],
      "metadata": {
        "id": "L4PxGqPxDRsx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dic_letter_count = {i: {} for i in letter_dict.keys()}\n",
        "for key in dic_letter_count.keys():\n",
        "    dic_letter_count[key] = {i: 0 for i in dic_letter_count.keys()}\n",
        "\n",
        "for i in letter_dict.keys():\n",
        "    for x in words:\n",
        "        for y in range(len(x)-1):\n",
        "            if x[y] == i:\n",
        "                dic_letter_count[i][x[y+1]] += 1"
      ],
      "metadata": {
        "id": "834IA-s7kk42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Letter that follows dictionary to dataDrame and bar plot for each letter."
      ],
      "metadata": {
        "id": "dy-2Fx4WEi_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame.from_dict(dic_letter_count, orient='index')\n",
        "for row in df.index:\n",
        "    plt.figure()\n",
        "    plt.title(row)\n",
        "    plt.bar(df.columns, df.loc[row])"
      ],
      "metadata": {
        "id": "xSr7OV4rtzHL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}